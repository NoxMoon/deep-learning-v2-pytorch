{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breed Classification Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Background and Goal\n",
    "The project will focus on using deep learning to identify dog breed from a supplied dog image. In specific, when given an arbitary image, the algorithm should first identify if it is a dog or a human. If dog is detected, the code will return the estimate of breed. If human is detected, the code will return the resembling dog breed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set\n",
    "\n",
    "Two data set are provide by Udacity.\n",
    "1. Dog data set (https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip):\n",
    "    * 8351 dog images of 133 dog breed categories\n",
    "    * split into train, validation and test set, with 6680, 835, 836 images respectively.\n",
    "2. Human data set (http://vis-www.cs.umass.edu/lfw/lfw.tgz):\n",
    "    * 13233 human face images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposed Solution\n",
    "\n",
    "For detecting human or dog, we can use either image classification or object detection for this problem. As this is a pretty standard task, there are some existing implementations we can use directly. For example, we can use OpenCV's face detector for human detection.\n",
    "\n",
    "For dog breed classification, we can either train a nerual network from scratch or use transfer learning. The architecture nerual network of image classification typically consists of two part: feature extraction part and classifier part. The feature extraction part usually consists of a series of convolutional layers. The classifier usually consists of a few fully-connected/linear layers and the final layer would out put N_class numbers that can be used to compute loss function. For transfer learning, we can use a pretrained model, e.g. VGG16, ResNet50, change the last layer to match the number of classis in our problem. We will fix the weight of feature extraction part, and fine tune the classifier part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Model\n",
    "\n",
    "For dog breed classification, I tried to use AWS Sagemaker's build in image classification. I choose to use pretrained 18 layer network and fine tune the last layer. However, I can only archieve 1% accuracy on both training and validation, and early stopping was triggered before 30 epochs. The algorithm is kind of black-box to me and I am not sure how to improve it.\n",
    "\n",
    "Below are my code to start a image classification training job on Sagemaker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic = sagemaker.estimator.Estimator(\n",
    "                training_image,\n",
    "                role, \n",
    "                train_instance_count=1, \n",
    "                train_instance_type='ml.p2.xlarge',\n",
    "                train_volume_size = 50,\n",
    "                train_max_run = 360000,\n",
    "                input_mode= 'File',\n",
    "                output_path=s3_output_location,\n",
    "                sagemaker_session=sess,\n",
    "                base_job_name='project-dog',\n",
    "                    )\n",
    "ic.set_hyperparameters(num_layers=18,\n",
    "                             use_pretrained_model=1,\n",
    "                             image_shape = \"3,224,224\",\n",
    "                             num_classes=133,\n",
    "                             num_training_samples=6678,\n",
    "                             mini_batch_size=32,\n",
    "                             epochs=30,\n",
    "                             learning_rate=0.001,\n",
    "                             precision_dtype='float32',\n",
    "                             early_stopping=True,\n",
    "                             optimizer='adam',\n",
    "                             checkpoint_frequency=5,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "For dog/human detection, we can evaluate the accuracy. We also would like to focus on false positive and false negative rate. For example, given a set of human images, the human detector can failed to detect how many images. Given a set of dog images, how many images the human detector may mistakenly detect dog as human.\n",
    "\n",
    "For dog breed classification, as this is a multiclass classification, we can use cross-entropy as optimization and evaluation metric. We can also use accuracy as evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
